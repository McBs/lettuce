{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import lettuce\n",
    "import lettuce as lt\n",
    "from lettuce import D3Q19, Lattice, UnitConversion, BGKCollision, StandardStreaming, Simulation, IncompressibleKineticEnergy, WallQuantities, SimulationHWBB, GlobalMeanUXReporter, AdaptiveForce\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.479288648Z",
     "start_time": "2025-06-23T12:46:03.036531704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class WallQuantitiesInternal:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lattice,\n",
    "        flow,\n",
    "        molecular_viscosity,\n",
    "        y_lattice=1.0,\n",
    "        wall='bottom',\n",
    "        kappa=0.41,\n",
    "        B=5.2,\n",
    "        max_iter=100,\n",
    "        tol=1e-8,\n",
    "        use_smagorinsky=False,\n",
    "        smagorinsky_collision_instance=None\n",
    "    ):\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.nu = molecular_viscosity\n",
    "        self.y = y_lattice\n",
    "        self.wall = wall\n",
    "        self.kappa = kappa\n",
    "        self.B = B\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.normal_axis = 1  # y-Achse\n",
    "\n",
    "        self.use_smagorinsky = use_smagorinsky\n",
    "        if self.use_smagorinsky:\n",
    "            if smagorinsky_collision_instance is None:\n",
    "                raise ValueError(\"Smagorinsky collision instance required if use_smagorinsky=True.\")\n",
    "            self.smagorinsky_collision = smagorinsky_collision_instance\n",
    "\n",
    "    def spalding_law(self, y_plus_grid_dist, u_mag_wall_parallel, nu_effective):\n",
    "        y_plus_grid_dist = torch.tensor(y_plus_grid_dist, device=u_mag_wall_parallel.device, dtype=u_mag_wall_parallel.dtype)\n",
    "        u_plus = (y_plus_grid_dist * u_mag_wall_parallel / nu_effective).clamp(min=1e-4).detach().clone().requires_grad_(False)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            ku = self.kappa * u_plus\n",
    "            exp_ku = torch.exp(ku)\n",
    "            spalding_term = u_plus + torch.exp(torch.tensor(-self.kappa * self.B, device=u_plus.device, dtype=u_plus.dtype)) * (\n",
    "                exp_ku - 1 - ku - 0.5 * ku**2 - (1/6) * ku**3\n",
    "            )\n",
    "            rhs = (y_plus_grid_dist * u_mag_wall_parallel) / (nu_effective * u_plus.clamp(min=1e-8))\n",
    "            f_eq_solve = spalding_term - rhs\n",
    "\n",
    "            d_spalding_term = 1 + torch.exp(torch.tensor(-self.kappa * self.B, device=u_plus.device, dtype=u_plus.dtype)) * (\n",
    "                self.kappa * exp_ku - self.kappa - self.kappa**2 * u_plus - 0.5 * self.kappa**3 * u_plus**2\n",
    "            )\n",
    "            d_rhs = - (y_plus_grid_dist * u_mag_wall_parallel) / (nu_effective * u_plus.clamp(min=1e-8)**2)\n",
    "            df_eq_solve = d_spalding_term - d_rhs\n",
    "\n",
    "            delta = f_eq_solve / torch.where(torch.abs(df_eq_solve) < 1e-10, torch.tensor(1e-10, device=f_eq_solve.device), df_eq_solve)\n",
    "            u_plus = (u_plus - delta).clamp(min=1e-4)\n",
    "\n",
    "            if torch.max(torch.abs(delta)) < self.tol:\n",
    "                break\n",
    "        return u_plus\n",
    "\n",
    "    def __call__(self, f_full_grid):\n",
    "        rho_full = self.lattice.rho(f_full_grid)\n",
    "        u_full = self.lattice.u(f_full_grid)\n",
    "\n",
    "        if rho_full.ndim == self.lattice.D + 1 and rho_full.shape[0] == 1:\n",
    "            rho_full = rho_full.squeeze(0)\n",
    "        if u_full.ndim == self.lattice.D + 1 and u_full.shape[1] == 1:\n",
    "            u_full = u_full.squeeze(1)\n",
    "\n",
    "        grid_spatial_dims = list(range(self.lattice.D))\n",
    "        spatial_idx_slice = [slice(None)] * self.lattice.D\n",
    "        spatial_idx_slice[self.normal_axis] = 1 if self.wall == \"bottom\" else -2\n",
    "\n",
    "        rho_f = rho_full[tuple(spatial_idx_slice)].flatten()\n",
    "        u_x_f = u_full[0][tuple(spatial_idx_slice)].flatten()\n",
    "        u_y_f = u_full[1][tuple(spatial_idx_slice)].flatten()\n",
    "        u_z_f = u_full[2][tuple(spatial_idx_slice)].flatten() if self.lattice.D == 3 else torch.zeros_like(u_x_f)\n",
    "\n",
    "        u_mag_wall_parallel = torch.sqrt(u_x_f**2 + u_z_f**2).clamp(min=1e-10)\n",
    "\n",
    "        if self.use_smagorinsky:\n",
    "            tau_eff_scalar = self.smagorinsky_collision.tau_eff\n",
    "            shape = u_full[0].shape\n",
    "            tau_eff_full_grid = torch.full(shape, tau_eff_scalar, device=u_full.device, dtype=u_full.dtype)\n",
    "            nu_eff_full_grid = (tau_eff_full_grid - 0.5) / 3.0\n",
    "            nu_eff_wall_layer = nu_eff_full_grid[tuple(spatial_idx_slice)].flatten()\n",
    "        else:\n",
    "            nu_eff_wall_layer = torch.full_like(u_mag_wall_parallel, self.nu)\n",
    "\n",
    "        u_plus = self.spalding_law(self.y, u_mag_wall_parallel, nu_eff_wall_layer)\n",
    "        u_tau = (u_mag_wall_parallel / u_plus).clamp(min=1e-8)\n",
    "        tau_w = rho_f * u_tau**2\n",
    "\n",
    "        safe_u_mag = torch.where(u_mag_wall_parallel < 1e-10, torch.tensor(1.0, device=u_mag_wall_parallel.device, dtype=u_mag_wall_parallel.dtype), u_mag_wall_parallel)\n",
    "        tau_x = - (u_x_f / safe_u_mag) * tau_w\n",
    "        tau_z = - (u_z_f / safe_u_mag) * tau_w\n",
    "\n",
    "        tau_x_wall = torch.zeros_like(u_full[0])\n",
    "        tau_z_wall = torch.zeros_like(u_full[2] if self.lattice.D == 3 else u_full[0])\n",
    "\n",
    "        if self.lattice.D == 3:\n",
    "            target_shape_slice = tau_x_wall[tuple(spatial_idx_slice)].shape\n",
    "            tau_x_wall[tuple(spatial_idx_slice)] = tau_x.reshape(target_shape_slice)\n",
    "            tau_z_wall[tuple(spatial_idx_slice)] = tau_z.reshape(target_shape_slice)\n",
    "        else:\n",
    "            raise ValueError(\"Only 3D supported for this current implementation of WallQuantitiesInternal.\")\n",
    "\n",
    "        return {\n",
    "            \"tau_x\": tau_x_wall,\n",
    "            \"tau_z\": tau_z_wall,\n",
    "            \"u_tau\": u_tau\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.495816973Z",
     "start_time": "2025-06-23T12:46:04.492930314Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class WallFunctionBoundaryTest:\n",
    "    def __init__(self, mask, lattice, flow, wall='bottom', apply_wfb_correction=True,\n",
    "                 smagorinsky_collision_instance=None):\n",
    "        self.mask = lattice.convert_to_tensor(mask)\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.wall = wall\n",
    "        self.apply_wfb_correction = apply_wfb_correction\n",
    "        self.normal_axis = 1\n",
    "\n",
    "        self.tau_x = None\n",
    "        self.tau_z = None\n",
    "        self.u_tau_mean = None\n",
    "        self.y_plus_mean = None\n",
    "        self.Re_tau_mean = None\n",
    "\n",
    "        self.use_smagorinsky = smagorinsky_collision_instance is not None\n",
    "\n",
    "        # Konstruktion der WallQuantitiesInternal â€“ immer\n",
    "        self.wall_quantities_internal = WallQuantitiesInternal(\n",
    "            lattice=self.lattice,\n",
    "            flow=self.flow,\n",
    "            molecular_viscosity=self.flow.units.viscosity_lu,\n",
    "            wall=self.wall,\n",
    "            y_lattice=1.0,\n",
    "            use_smagorinsky=self.use_smagorinsky,\n",
    "            smagorinsky_collision_instance=smagorinsky_collision_instance\n",
    "        )\n",
    "\n",
    "    def set_smagorinsky_collision(self, collision):\n",
    "        self.smagorinsky_collision = collision\n",
    "        self.wall_quantities_internal = WallQuantitiesInternal(\n",
    "            lattice=self.lattice,\n",
    "            flow=self.flow,\n",
    "            molecular_viscosity=self.flow.units.viscosity_lu,\n",
    "            wall=self.wall,\n",
    "            y_lattice=1.0,\n",
    "            smagorinsky_collision_instance=collision\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, f):\n",
    "        # --- 1. Klonen der Originalverteilungen fÃ¼r spÃ¤tere Korrektur ---\n",
    "        if self.wall == 'bottom':\n",
    "            f17_old = f[17, self.mask].clone()\n",
    "            f16_old = f[16, self.mask].clone()\n",
    "            f10_old = f[10, self.mask].clone()\n",
    "            f8_old  = f[8, self.mask].clone()\n",
    "        elif self.wall == 'top':\n",
    "            f15_old = f[15, self.mask].clone()\n",
    "            f18_old = f[18, self.mask].clone()\n",
    "            f7_old  = f[7, self.mask].clone()\n",
    "            f9_old  = f[9, self.mask].clone()\n",
    "        else:\n",
    "            raise ValueError(\"wall must be 'bottom' or 'top'\")\n",
    "\n",
    "        # --- 2. Wall Quantities intern berechnen ---\n",
    "        results = self.wall_quantities_internal(f)\n",
    "        tau_x_field = 0.5 * results[\"tau_x\"]\n",
    "        tau_z_field = 0.5 * results[\"tau_z\"]\n",
    "\n",
    "        # --- 3. Free-Slip Bounce-Back anwenden ---\n",
    "        f = torch.where(self.mask, f[self.lattice.stencil.opposite], f)\n",
    "\n",
    "        # --- 4. Additive Wandkorrektur ---\n",
    "        if self.wall == 'bottom':\n",
    "            f[15, self.mask] = f17_old + tau_z_field[self.mask]\n",
    "            f[16, self.mask] = f17_old + tau_z_field[self.mask]\n",
    "            f[18, self.mask] = f16_old - tau_z_field[self.mask]\n",
    "            f[8,  self.mask] = f16_old - tau_z_field[self.mask]\n",
    "            f[7,  self.mask] = f10_old + tau_x_field[self.mask]\n",
    "            f[17, self.mask] = f10_old + tau_x_field[self.mask]\n",
    "            f[9,  self.mask] = f8_old - tau_x_field[self.mask]\n",
    "            f[10, self.mask] = f8_old - tau_x_field[self.mask]\n",
    "        elif self.wall == 'top':\n",
    "            f[17, self.mask] = f15_old + tau_z_field[self.mask]\n",
    "            f[18, self.mask] = f15_old + tau_z_field[self.mask]\n",
    "            f[16, self.mask] = f18_old - tau_z_field[self.mask]\n",
    "            f[9,  self.mask] = f18_old - tau_z_field[self.mask]\n",
    "            f[10, self.mask] = f7_old + tau_x_field[self.mask]\n",
    "            f[15, self.mask] = f7_old + tau_x_field[self.mask]\n",
    "            f[8,  self.mask] = f9_old - tau_x_field[self.mask]\n",
    "            f[7,  self.mask] = f9_old - tau_x_field[self.mask]\n",
    "\n",
    "        # --- 5. Ergebnisse fÃ¼r Reporter speichern ---\n",
    "        self.tau_x = tau_x_field\n",
    "        self.tau_z = tau_z_field\n",
    "        self.u_tau_mean = results[\"u_tau\"].mean()\n",
    "        self.y_plus_mean = (self.wall_quantities_internal.y * results[\"u_tau\"] / self.wall_quantities_internal.nu).mean()\n",
    "        self.Re_tau_mean = (results[\"u_tau\"] * self.wall_quantities_internal.y / self.wall_quantities_internal.nu).mean()\n",
    "\n",
    "\n",
    "        return f\n",
    "\n",
    "    def make_no_collision_mask(self, f_shape):\n",
    "        \"\"\"\n",
    "        Diese Boundary-Methode liefert die Maske der Wandknoten,\n",
    "        auf denen der Kollisionsschritt der Hauptsimulation Ã¼bersprungen werden soll.\n",
    "        Diese Klasse operiert auf diesen Wandknoten selbst.\n",
    "        \"\"\"\n",
    "        assert self.mask.shape == f_shape[1:]\n",
    "        # KORREKTUR: Muss die Maske der eigenen Wandknoten (self.mask) zurÃ¼ckgeben.\n",
    "        return self.mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.522365097Z",
     "start_time": "2025-06-23T12:46:04.500022479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class ChannelFlow3DTest(object):\n",
    "    \"\"\"Flow class to simulate the flow around an object (mask) in 3D.\n",
    "    See documentation for :class:`~Obstacle2D` for details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, resolution_x, resolution_y, resolution_z, reynolds_number, mach_number, lattice, char_length_lu, boundary):\n",
    "        self.resolution_x = resolution_x\n",
    "        self.resolution_y = resolution_y\n",
    "        self.resolution_z = resolution_z\n",
    "\n",
    "        self.units = UnitConversion(\n",
    "            lattice,\n",
    "            reynolds_number=reynolds_number,\n",
    "            mach_number=mach_number,\n",
    "            characteristic_length_lu=char_length_lu,\n",
    "            characteristic_length_pu=1,\n",
    "            characteristic_velocity_pu=1)\n",
    "\n",
    "        self._mask = np.zeros(shape=(self.resolution_x, self.resolution_y, self.resolution_z), dtype=bool)\n",
    "        self._boundary = boundary\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "    @mask.setter\n",
    "    def mask(self, m):\n",
    "        assert isinstance(m, np.ndarray) and m.shape == (self.resolution_x, self.resolution_y, self.resolution_z)\n",
    "        self._mask = m.astype(bool)\n",
    "\n",
    "    def initial_solution(self, grid):\n",
    "        xg, yg, zg = grid\n",
    "        p = np.ones_like(xg)[None, ...]\n",
    "        nx, ny, nz = self.resolution_x, self.resolution_y, self.resolution_z\n",
    "\n",
    "        u = np.zeros((3, nx, ny, nz))\n",
    "\n",
    "        # --- ðŸ“ Poiseuille-Profil (in x-Richtung) ---\n",
    "        y_normalized = yg / yg.max()\n",
    "        u_base = y_normalized * (1 - y_normalized)\n",
    "        u[0] = u_base * (1 - self.mask.astype(float))  # u_x = BasisstrÃ¶mung\n",
    "\n",
    "        # --- ðŸŽ›ï¸ Sinusmoden-StÃ¶rung (3D) ---\n",
    "        A_sin = 0.5  # 5% Amplitude\n",
    "        Lx, Ly, Lz = xg.max(), yg.max(), zg.max()\n",
    "        sinus_modes = [(1, 1, 1), (2, 2, 3), (3, 2, 1)]\n",
    "\n",
    "        for kx, ky, kz in sinus_modes:\n",
    "            phase = 2 * np.pi * np.random.rand()\n",
    "            mode = np.sin(2 * np.pi * (kx * xg / Lx + ky * yg / Ly + kz * zg / Lz) + phase)\n",
    "            envelope = y_normalized * (1 - y_normalized)\n",
    "            u[0] += A_sin * mode * envelope  # nur u_x gestÃ¶rt, kannst du erweitern\n",
    "\n",
    "        # --- ðŸŒªï¸ Vektorpotential Ïˆ (3 Komponenten fÃ¼r Curl in 3D) ---\n",
    "        A_psi = 1\n",
    "        random_psi = ((np.random.rand(3, nx, ny, nz) - 0.5) * 2)\n",
    "\n",
    "        # Wandgewichtung in y und z\n",
    "        y_weight = np.exp(-((y_normalized - 0.0) / 0.2) ** 2) + np.exp(-((y_normalized - 1.0) / 0.2) ** 2)\n",
    "        y_weight /= y_weight.max()\n",
    "\n",
    "        z_normalized = zg / zg.max()\n",
    "        z_weight = np.exp(-((z_normalized - 0.5) / 0.3) ** 2)\n",
    "        z_weight /= z_weight.max()\n",
    "\n",
    "        weight = y_weight * z_weight\n",
    "        random_psi *= weight[None, :, :, :]\n",
    "\n",
    "        # FFT-Filterung (3D)\n",
    "        k0 = np.sqrt(nx ** 2 + ny ** 2 + nz ** 2)\n",
    "        psi_filtered = np.empty_like(random_psi)\n",
    "        for d in range(3):\n",
    "            psi_hat = np.fft.fftn(random_psi[d])\n",
    "            kx = np.fft.fftfreq(nx).reshape(-1, 1, 1)\n",
    "            ky = np.fft.fftfreq(ny).reshape(1, -1, 1)\n",
    "            kz = np.fft.fftfreq(nz).reshape(1, 1, -1)\n",
    "            kabs = np.sqrt((kx * nx) ** 2 + (ky * ny) ** 2 + (kz * nz) ** 2)\n",
    "            filter_mask = np.exp(-kabs / (0.3 * k0))\n",
    "            psi_hat *= filter_mask\n",
    "            psi_hat[0, 0, 0] = 0\n",
    "            psi_filtered[d] = np.real(np.fft.ifftn(psi_hat))\n",
    "\n",
    "        # --- ðŸŒ€ Curl(Ïˆ): u = âˆ‡ Ã— Ïˆ ---\n",
    "        u_psi = np.zeros_like(u)\n",
    "        u_psi[0] = np.gradient(psi_filtered[2], axis=1) - np.gradient(psi_filtered[1], axis=2)  # u_x\n",
    "        u_psi[1] = np.gradient(psi_filtered[0], axis=2) - np.gradient(psi_filtered[2], axis=0)  # u_y\n",
    "        u_psi[2] = np.gradient(psi_filtered[1], axis=0) - np.gradient(psi_filtered[0], axis=1)  # u_z\n",
    "\n",
    "        # Normierung\n",
    "        umax_psi = np.max(np.sqrt(np.sum(u_psi ** 2, axis=0)))\n",
    "        if umax_psi > 0:\n",
    "            u_psi *= A_psi / umax_psi\n",
    "\n",
    "        # --- Ãœberlagerung: Basis + Sine + Curl ---\n",
    "        u += u_psi\n",
    "        # 2D: Nullsetzen der Wandgeschwindigkeit\n",
    "\n",
    "        u[:, :, 0, :] = 0.0  # untere Wand (y=0)\n",
    "        u[:, :, -1, :] = 0.0  # obere Wand (y=Ny-1)\n",
    "\n",
    "        return p, u\n",
    "\n",
    "    @property\n",
    "    def grid(self):\n",
    "        stop_x = self.resolution_x / self.units.characteristic_length_lu\n",
    "        stop_y = self.resolution_y / self.units.characteristic_length_lu\n",
    "        stop_z = self.resolution_z / self.units.characteristic_length_lu\n",
    "\n",
    "        x = np.linspace(0, stop_x, num=self.resolution_x, endpoint=False)\n",
    "        y = np.linspace(0, stop_y, num=self.resolution_y, endpoint=False)\n",
    "        z = np.linspace(0, stop_z, num=self.resolution_z, endpoint=False)\n",
    "\n",
    "        return np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "    @property\n",
    "    def boundaries(self):\n",
    "        x, y, z = self.grid  # Jetzt auch z\n",
    "        Ny = y.shape[1]  # HÃ¶he des Kanals in y-Richtung\n",
    "\n",
    "        # Bounce-Back-Maske (WÃ¤nde bei y=0 und y=Ny-1)\n",
    "        # In 3D mÃ¼ssen wir die Maske Ã¼ber alle x- und z-Koordinaten ausdehnen.\n",
    "        mask_bb = np.zeros_like(x, dtype=bool)\n",
    "        mask_bb[:, 0, :] = True  # untere Wand (y=0)\n",
    "        mask_bb[:, Ny - 1, :] = True  # obere Wand (y=Ny-1)\n",
    "\n",
    "        # Wall-Function-Masken (erste Fluidzellen direkt an der Wand)\n",
    "        # Auch hier Ã¼ber alle x- und z-Koordinaten ausdehnen.\n",
    "        mask_bottom = np.zeros_like(x, dtype=bool)\n",
    "        mask_bottom[:, 0, :] = True  # Erste Fluidzelle Ã¼ber der unteren Wand (y=1)\n",
    "\n",
    "        mask_top = np.zeros_like(x, dtype=bool)\n",
    "        mask_top[:, Ny - 1, :] = True  # Erste Fluidzelle unter der oberen Wand (y=Ny-2)\n",
    "\n",
    "        # Das Boundary-Objekt fÃ¼r Bounce-Back\n",
    "\n",
    "        if self._boundary == \"wallfunction\":\n",
    "            bb = [\n",
    "    WallFunctionBoundaryTest(mask_bottom, self.units.lattice, self, wall='bottom'),\n",
    "    WallFunctionBoundaryTest(mask_top,    self.units.lattice, self, wall='top')\n",
    "]\n",
    "\n",
    "        return bb\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.525099263Z",
     "start_time": "2025-06-23T12:46:04.521467711Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class WallQuantitiesTest:\n",
    "    def __init__(self, lattice, flow, boundary):\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.boundary = boundary\n",
    "\n",
    "    def __call__(self, f):\n",
    "        if not hasattr(self.boundary, \"wall_quantities_internal\"):\n",
    "            print(\"âš ï¸ `wall_quantities_internal` noch nicht gesetzt â€“ WallQuantitiesTest Ã¼berspringt Schritt.\")\n",
    "            return torch.zeros(5)\n",
    "\n",
    "        result = self.boundary.wall_quantities_internal(f)\n",
    "        u_tau = result[\"u_tau\"]\n",
    "        y = self.boundary.wall_quantities_internal.y\n",
    "        nu = self.boundary.wall_quantities_internal.nu\n",
    "        print(\"Re_Tau=\" + str(torch.mean(y * u_tau / nu)))\n",
    "        print(\"y+=\" + str(torch.mean(u_tau * y / nu)))\n",
    "        return torch.tensor([\n",
    "            result[\"tau_x\"].mean(),\n",
    "            result[\"tau_z\"].mean(),\n",
    "            u_tau.mean(),\n",
    "            (y * u_tau / nu).mean(),\n",
    "            (u_tau * y / nu).mean()\n",
    "        ])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.572974674Z",
     "start_time": "2025-06-23T12:46:04.525510671Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICH FUNKTIONIERE MIT PULLEN\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--vtkdir\", type=str, default=\"./output/\")\n",
    "parser.add_argument(\"--csvdir\", type=str, default=\"./output/\")\n",
    "parser.add_argument(\"--nout\", type=int, default=100)\n",
    "parser.add_argument(\"--nvtk\", type=int, default=100)\n",
    "parser.add_argument(\"--tmax\", type=int, default=0.1)\n",
    "parser.add_argument(\"--Re\", type=int, default=13800)\n",
    "parser.add_argument(\"--collision_operator\", type=str, default=\"Smag\")\n",
    "parser.add_argument(\"--Precision\", type=str, default=\"Double\")\n",
    "parser.add_argument(\"--Mach\", type=float, default=0.1)\n",
    "parser.add_argument(\"--h\", type=int, default=20, help=\"Halbe KanalhÃ¶he in LU\")\n",
    "parser.add_argument(\"--bbtype\", type=str, default=\"wallfunction\", choices=[\"halfway\", \"fullway\", \"wallfunction\", \"freeslip\"],\n",
    "                    help=\"Typ der Bounce-Back-Randbedingung\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "args = vars(args)\n",
    "\n",
    "print(\"ICH FUNKTIONIERE MIT PULLEN\")\n",
    "\n",
    "\n",
    "\n",
    "# Einheiten und AuflÃ¶sung\n",
    "h = args[\"h\"]                      # KanalhalbhÃ¶he in LU\n",
    "res_y = 2 * h                     # y: volle KanalhÃ¶he\n",
    "res_x = int(2*np.pi * h)\n",
    "res_z = int(np.pi * h)\n",
    "\n",
    "# Restliche Parameter\n",
    "Re = args[\"Re\"]\n",
    "basedir = args[\"vtkdir\"]\n",
    "csvdir = args[\"csvdir\"]\n",
    "nout = args[\"nout\"]\n",
    "nvtk = args[\"nvtk\"]\n",
    "tmax = args[\"tmax\"]\n",
    "Precision = args[\"Precision\"]\n",
    "collision_operator = args[\"collision_operator\"]\n",
    "Mach = args[\"Mach\"]\n",
    "bbtype = args[\"bbtype\"]\n",
    "# PrÃ¤zision\n",
    "if Precision == \"Single\":\n",
    "    dtype = torch.float32\n",
    "elif Precision == \"Double\":\n",
    "    dtype = torch.float64\n",
    "elif Precision == \"Half\":\n",
    "    dtype = torch.float16\n",
    "\n",
    "\n",
    "Re_tau = 180\n",
    "\n",
    "smagorinsky_constant = 0.17\n",
    "\n",
    "delta_x = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.573529249Z",
     "start_time": "2025-06-23T12:46:04.568670315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ist nicht verfÃ¼gbar. Verwende CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/envs/lettuce/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035891/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps     time     GlobalMeanUXReporter\n",
      "steps     time     WallQuantitiesTest\n",
      "steps     time     WallQuantitiesTest\n",
      "steps     time     IncompressibleKineticEnergy\n",
      "Starte Simulation fÃ¼r 69 Schritte auf cpu...\n",
      "Re_Tau=tensor(6.1804, dtype=torch.float64)\n",
      "y+=tensor(6.1804, dtype=torch.float64)\n",
      "Re_Tau=tensor(6.1518, dtype=torch.float64)\n",
      "y+=tensor(6.1518, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9414, dtype=torch.float64)\n",
      "y+=tensor(4.9414, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9294, dtype=torch.float64)\n",
      "y+=tensor(4.9294, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.7386, dtype=torch.float64)\n",
      "y+=tensor(4.7386, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.7584, dtype=torch.float64)\n",
      "y+=tensor(4.7584, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.8746, dtype=torch.float64)\n",
      "y+=tensor(4.8746, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.8806, dtype=torch.float64)\n",
      "y+=tensor(4.8806, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0086, dtype=torch.float64)\n",
      "y+=tensor(5.0086, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0505, dtype=torch.float64)\n",
      "y+=tensor(5.0505, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9742, dtype=torch.float64)\n",
      "y+=tensor(4.9742, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0163, dtype=torch.float64)\n",
      "y+=tensor(5.0163, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0787, dtype=torch.float64)\n",
      "y+=tensor(5.0787, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0682, dtype=torch.float64)\n",
      "y+=tensor(5.0682, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.8929, dtype=torch.float64)\n",
      "y+=tensor(4.8929, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.8816, dtype=torch.float64)\n",
      "y+=tensor(4.8816, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0228, dtype=torch.float64)\n",
      "y+=tensor(5.0228, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0272, dtype=torch.float64)\n",
      "y+=tensor(5.0272, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9104, dtype=torch.float64)\n",
      "y+=tensor(4.9104, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9149, dtype=torch.float64)\n",
      "y+=tensor(4.9149, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0002, dtype=torch.float64)\n",
      "y+=tensor(5.0002, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0221, dtype=torch.float64)\n",
      "y+=tensor(5.0221, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9201, dtype=torch.float64)\n",
      "y+=tensor(4.9201, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9163, dtype=torch.float64)\n",
      "y+=tensor(4.9163, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1184, dtype=torch.float64)\n",
      "y+=tensor(5.1184, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1255, dtype=torch.float64)\n",
      "y+=tensor(5.1255, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9665, dtype=torch.float64)\n",
      "y+=tensor(4.9665, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9761, dtype=torch.float64)\n",
      "y+=tensor(4.9761, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0544, dtype=torch.float64)\n",
      "y+=tensor(5.0544, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0678, dtype=torch.float64)\n",
      "y+=tensor(5.0678, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9741, dtype=torch.float64)\n",
      "y+=tensor(4.9741, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9672, dtype=torch.float64)\n",
      "y+=tensor(4.9672, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1737, dtype=torch.float64)\n",
      "y+=tensor(5.1737, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1796, dtype=torch.float64)\n",
      "y+=tensor(5.1796, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0357, dtype=torch.float64)\n",
      "y+=tensor(5.0357, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0649, dtype=torch.float64)\n",
      "y+=tensor(5.0649, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2255, dtype=torch.float64)\n",
      "y+=tensor(5.2255, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2306, dtype=torch.float64)\n",
      "y+=tensor(5.2306, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0426, dtype=torch.float64)\n",
      "y+=tensor(5.0426, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0276, dtype=torch.float64)\n",
      "y+=tensor(5.0276, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2142, dtype=torch.float64)\n",
      "y+=tensor(5.2142, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2057, dtype=torch.float64)\n",
      "y+=tensor(5.2057, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1325, dtype=torch.float64)\n",
      "y+=tensor(5.1325, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1265, dtype=torch.float64)\n",
      "y+=tensor(5.1265, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2513, dtype=torch.float64)\n",
      "y+=tensor(5.2513, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2519, dtype=torch.float64)\n",
      "y+=tensor(5.2519, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1493, dtype=torch.float64)\n",
      "y+=tensor(5.1493, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1304, dtype=torch.float64)\n",
      "y+=tensor(5.1304, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.3133, dtype=torch.float64)\n",
      "y+=tensor(5.3133, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.3075, dtype=torch.float64)\n",
      "y+=tensor(5.3075, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1792, dtype=torch.float64)\n",
      "y+=tensor(5.1792, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1547, dtype=torch.float64)\n",
      "y+=tensor(5.1547, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.3022, dtype=torch.float64)\n",
      "y+=tensor(5.3022, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2799, dtype=torch.float64)\n",
      "y+=tensor(5.2799, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1772, dtype=torch.float64)\n",
      "y+=tensor(5.1772, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1403, dtype=torch.float64)\n",
      "y+=tensor(5.1403, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.3054, dtype=torch.float64)\n",
      "y+=tensor(5.3054, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2882, dtype=torch.float64)\n",
      "y+=tensor(5.2882, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1825, dtype=torch.float64)\n",
      "y+=tensor(5.1825, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1633, dtype=torch.float64)\n",
      "y+=tensor(5.1633, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.3037, dtype=torch.float64)\n",
      "y+=tensor(5.3037, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2814, dtype=torch.float64)\n",
      "y+=tensor(5.2814, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1601, dtype=torch.float64)\n",
      "y+=tensor(5.1601, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1178, dtype=torch.float64)\n",
      "y+=tensor(5.1178, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2695, dtype=torch.float64)\n",
      "y+=tensor(5.2695, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2366, dtype=torch.float64)\n",
      "y+=tensor(5.2366, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1323, dtype=torch.float64)\n",
      "y+=tensor(5.1323, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0851, dtype=torch.float64)\n",
      "y+=tensor(5.0851, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2555, dtype=torch.float64)\n",
      "y+=tensor(5.2555, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2296, dtype=torch.float64)\n",
      "y+=tensor(5.2296, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0929, dtype=torch.float64)\n",
      "y+=tensor(5.0929, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0621, dtype=torch.float64)\n",
      "y+=tensor(5.0621, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2354, dtype=torch.float64)\n",
      "y+=tensor(5.2354, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2201, dtype=torch.float64)\n",
      "y+=tensor(5.2201, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0918, dtype=torch.float64)\n",
      "y+=tensor(5.0918, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0661, dtype=torch.float64)\n",
      "y+=tensor(5.0661, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2292, dtype=torch.float64)\n",
      "y+=tensor(5.2292, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2123, dtype=torch.float64)\n",
      "y+=tensor(5.2123, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1206, dtype=torch.float64)\n",
      "y+=tensor(5.1206, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0962, dtype=torch.float64)\n",
      "y+=tensor(5.0962, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2366, dtype=torch.float64)\n",
      "y+=tensor(5.2366, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2313, dtype=torch.float64)\n",
      "y+=tensor(5.2313, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1118, dtype=torch.float64)\n",
      "y+=tensor(5.1118, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0995, dtype=torch.float64)\n",
      "y+=tensor(5.0995, dtype=torch.float64)\n",
      "âš ï¸ u_tau_mean nicht verfÃ¼gbar. AdaptiveForce Ã¼berspringt Kraftberechnung.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 117\u001B[0m\n\u001B[1;32m    113\u001B[0m wfb_top(simulation\u001B[38;5;241m.\u001B[39mf)\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarte Simulation fÃ¼r \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msteps\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Schritte auf \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 117\u001B[0m mlups \u001B[38;5;241m=\u001B[39m \u001B[43msimulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSimulation beendet. MLUPS: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmlups\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    119\u001B[0m wq_top \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(simulation\u001B[38;5;241m.\u001B[39mreporters[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mout)\n",
      "File \u001B[0;32m~/lettuce/lettuce/simulation.py:84\u001B[0m, in \u001B[0;36mSimulation.step\u001B[0;34m(self, num_steps)\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mno_collision_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollision(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf))\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m boundary \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_boundaries:\n\u001B[0;32m---> 84\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mboundary\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report()\n\u001B[1;32m     90\u001B[0m end \u001B[38;5;241m=\u001B[39m timer()\n",
      "Cell \u001B[0;32mIn[3], line 59\u001B[0m, in \u001B[0;36mWallFunctionBoundaryTest.__call__\u001B[0;34m(self, f)\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwall must be \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbottom\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m# --- 2. Wall Quantities intern berechnen ---\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwall_quantities_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m tau_x_field \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtau_x\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     61\u001B[0m tau_z_field \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtau_z\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "Cell \u001B[0;32mIn[2], line 90\u001B[0m, in \u001B[0;36mWallQuantitiesInternal.__call__\u001B[0;34m(self, f_full_grid)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     88\u001B[0m     nu_eff_wall_layer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull_like(u_mag_wall_parallel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnu)\n\u001B[0;32m---> 90\u001B[0m u_plus \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspalding_law\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mu_mag_wall_parallel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnu_eff_wall_layer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m u_tau \u001B[38;5;241m=\u001B[39m (u_mag_wall_parallel \u001B[38;5;241m/\u001B[39m u_plus)\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-8\u001B[39m)\n\u001B[1;32m     92\u001B[0m tau_w \u001B[38;5;241m=\u001B[39m rho_f \u001B[38;5;241m*\u001B[39m u_tau\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\n",
      "Cell \u001B[0;32mIn[2], line 55\u001B[0m, in \u001B[0;36mWallQuantitiesInternal.spalding_law\u001B[0;34m(self, y_plus_grid_dist, u_mag_wall_parallel, nu_effective)\u001B[0m\n\u001B[1;32m     52\u001B[0m df_eq_solve \u001B[38;5;241m=\u001B[39m d_spalding_term \u001B[38;5;241m-\u001B[39m d_rhs\n\u001B[1;32m     54\u001B[0m delta \u001B[38;5;241m=\u001B[39m f_eq_solve \u001B[38;5;241m/\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(torch\u001B[38;5;241m.\u001B[39mabs(df_eq_solve) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1e-10\u001B[39m, torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;241m1e-10\u001B[39m, device\u001B[38;5;241m=\u001B[39mf_eq_solve\u001B[38;5;241m.\u001B[39mdevice), df_eq_solve)\n\u001B[0;32m---> 55\u001B[0m u_plus \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mu_plus\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdelta\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclamp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mmax(torch\u001B[38;5;241m.\u001B[39mabs(delta)) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtol:\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"CUDA ist verfÃ¼gbar. Verwende GPU.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CUDA ist nicht verfÃ¼gbar. Verwende CPU.\")\n",
    "\n",
    "dtype = torch.float64 # FÃ¼r StabilitÃ¤t bei hohen Re\n",
    "\n",
    "# --- ðŸ§± Lattice & Flow Initialisierung ---\n",
    "# D3Q19() muss instanziiert werden. Lattice bekommt die Instanz.\n",
    "lattice = Lattice(D3Q19(), device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flow = ChannelFlow3DTest(\n",
    "    resolution_x=res_x,\n",
    "    resolution_y=res_y,\n",
    "    resolution_z=res_z,\n",
    "    reynolds_number=Re, # Re_bulk\n",
    "    mach_number=Mach, # Physikalische Mach-Zahl\n",
    "    lattice=lattice,\n",
    "    char_length_lu=res_y, # Charakteristische LÃ¤nge in LU ist gesamte HÃ¶he 2H\n",
    "    boundary=bbtype # Signalisiert dem flow.boundaries, welche Boundary-Art erstellt wird\n",
    ")\n",
    "\n",
    "# --- NEUE KOMPONENTEN FÃœR ADAPTIVES FORCING ---\n",
    "\n",
    "# 1. Reporter, die die benÃ¶tigten Mittelwerte liefern\n",
    "# Diese Reporter mÃ¼ssen die Werte als zugÃ¤ngliche Attribute speichern (z.B. self.last_u_tau_spatial_mean)\n",
    "# Stellen Sie sicher, dass Ihre WallQuantities.__call__ diese Attribute setzt.\n",
    "# Beispiel fÃ¼r WallQuantities.__call__ Erweiterung:\n",
    "# class WallQuantities(...):\n",
    "#     # ...\n",
    "#     def __call__(self, f):\n",
    "#         # ... (alle Berechnungen von u_tau_current) ...\n",
    "#         self.last_u_tau_spatial_mean = torch.mean(u_tau_current).item() # HIER HINZUFÃœGEN\n",
    "#         # ... return torch.zeros(4,...)\n",
    "\n",
    "# Globaler Reporter fÃ¼r mittlere U_x Ã¼ber die DomÃ¤ne\n",
    "global_mean_ux_reporter = GlobalMeanUXReporter(lattice, flow)\n",
    "\n",
    "wfb_bottom = flow.boundaries[0]\n",
    "wfb_top = flow.boundaries[1]\n",
    "\n",
    "# Reporter, die nur \"lesen\"\n",
    "wq_bottom = WallQuantitiesTest( lattice=lattice, flow=flow, boundary=wfb_bottom)\n",
    "wq_top = WallQuantitiesTest( lattice=lattice, flow=flow, boundary=wfb_top)\n",
    "\n",
    "\n",
    "# 2. AdaptiveForce Klasse initialisieren\n",
    "# Sie braucht die Reporter, um die Werte zu bekommen.\n",
    "# target_u_m_pu kommt aus Paper Tabelle 2: 1.0 m/s\n",
    "adaptive_force_instance = AdaptiveForce(\n",
    "    lattice=lattice,\n",
    "    flow=flow,\n",
    "    target_u_m_lu=flow.units.convert_velocity_to_lu(1.0),\n",
    "    wall_bottom=wfb_bottom,\n",
    "    wall_top=wfb_top,\n",
    "    global_ux_reporter=global_mean_ux_reporter,\n",
    "    base_lbm_tau_lu = flow.units.relaxation_parameter_lu\n",
    ")\n",
    "# --- 3. Kollisionsmodell mit dem adaptiven Forcing initialisieren ---\n",
    "# Der 'force'-Parameter der SmagorinskyCollision erwartet ein Force-Objekt.\n",
    "collision = lettuce.SmagorinskyCollision(lattice, tau=flow.units.relaxation_parameter_lu, force=adaptive_force_instance)\n",
    "\n",
    "# flow schon initialisiert\n",
    "wfb_bottom = flow.boundaries[0]\n",
    "wfb_top = flow.boundaries[1]\n",
    "\n",
    "# Jetzt collision erzeugen\n",
    "\n",
    "# Dann collision in boundaries nachtragen\n",
    "wfb_bottom.set_smagorinsky_collision(collision)\n",
    "wfb_top.set_smagorinsky_collision(collision)\n",
    "\n",
    "# --- Simulation Setup ---\n",
    "streaming = StandardStreaming(lattice)\n",
    "simulation = Simulation(flow=flow, lattice=lattice, collision=collision, streaming=streaming)\n",
    "\n",
    "\n",
    "# --- ðŸ“Š Reporter zur Simulation hinzufÃ¼gen ---\n",
    "# Die Reporter, die als Input fÃ¼r AdaptiveForce dienen, MÃœSSEN vor dem AdaptiveForce-Aufruf in der Simulationsschleife aktualisiert werden.\n",
    "# Lettuce ruft die Reporter VOR den Boundaries und der Kollision auf, wenn sie als Simulation-Reporter hinzugefÃ¼gt werden.\n",
    "# Es ist wichtig, dass GlobalMeanUXReporter und WallQuantities zuerst in der Liste der Reporter stehen,\n",
    "# damit ihre 'last_...' Attribute aktualisiert werden, bevor AdaptiveForce in collision(f) aufgerufen wird.\n",
    "simulation.reporters.append(lt.ObservableReporter(global_mean_ux_reporter, interval=1, out=None))\n",
    "simulation.reporters.append(lt.ObservableReporter(wq_bottom, interval=1, out=None))\n",
    "simulation.reporters.append(lt.ObservableReporter(wq_top, interval=1, out=None))\n",
    "\n",
    "# Andere Reporter\n",
    "# Energy Reporter\n",
    "simulation.reporters.append(lt.ObservableReporter(lt.observables.IncompressibleKineticEnergy(lattice, flow), interval=100, out=None))\n",
    "# VTK Reporter\n",
    "\n",
    "steps = int(flow.units.convert_time_to_lu(tmax))\n",
    "\n",
    "\n",
    "vtk_reporter = lt.VTKReporter(\n",
    "    lattice=lattice, flow=flow, interval=max(1,int(steps/100)), filename_base=basedir + \"/output\"\n",
    ")\n",
    "simulation.reporters.append(vtk_reporter)\n",
    "\n",
    "\n",
    "# --- Simulation starten ---\n",
    "# Die Methode initialize_f_neq sollte nach der Initialisierung von Lattice und Flow aufgerufen werden,\n",
    "# um f mit dem initialen Geschwindigkeits- und Druckfeld zu fÃ¼llen.\n",
    "simulation.initialize_f_neq() # Initialisiert f in simulation.f\n",
    "\n",
    "# Vor dem ersten Schritt\n",
    "wfb_bottom(simulation.f)\n",
    "wfb_top(simulation.f)\n",
    "\n",
    "\n",
    "print(f\"Starte Simulation fÃ¼r {steps} Schritte auf {device}...\")\n",
    "mlups = simulation.step(num_steps=steps)\n",
    "print(f\"Simulation beendet. MLUPS: {mlups}\")\n",
    "wq_top = np.array(simulation.reporters[2].out)\n",
    "wq_bottom = np.array(simulation.reporters[1].out)\n",
    "ux_mean = np.array(simulation.reporters[0].out)\n",
    "\n",
    "\n",
    "\n",
    "with open(csvdir + 'uxmean.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(ux_mean)\n",
    "with open(csvdir + 'WallQuantitiesTop.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(wq_top)\n",
    "with open(csvdir + 'WallQuantitiesBottom.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(wq_bottom)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:22.884785296Z",
     "start_time": "2025-06-23T12:46:04.568936278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(ux_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Beispiel: Daten laden\n",
    "data = (wq_bottom+wq_top)/2\n",
    "time = data[:, 1]\n",
    "re_tau = data[:, 5]\n",
    "y_plus = data[:, 6]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time, re_tau, label=\"Re_tau (bottom)\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"Re_tau\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Re_tau Ã¼ber die Zeit\")\n",
    "plt.savefig(csvdir + \"retau.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time, y_plus, label=\"yâº (bottom)\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"yâº\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"yâº Ã¼ber die Zeit\")\n",
    "plt.savefig(csvdir + \"yplus.pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ux_mean[:, 1], flow.units.convert_velocity_to_pu(ux_mean[:, 2]))\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"ux_mean\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"ux_mean\")\n",
    "plt.savefig(csvdir + \"ux.pdf\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
